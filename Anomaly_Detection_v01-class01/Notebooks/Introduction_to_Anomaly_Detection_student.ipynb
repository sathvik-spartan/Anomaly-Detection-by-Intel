{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2019 Intel Corporation\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In Lesson 1, *Anomaly Detection: Introduction*, we learned that anomalies are outliers in the data that merit further scrutiny. We discussed basic scoring methods to identify outliers.\n",
    "\n",
    "We will continue our discussion by looking for outliers in one-dimensional (univariate) data. We will use both the z-score and modified z-score. We will examine the strengths and limitations of both approaches.\n",
    "\n",
    "# Learning Outcomes\n",
    "\n",
    "You should walk away from this Python tutorial with:\n",
    "1. An understanding of anomaly detection as an algorithm\n",
    "2. An appreciation of the importance of choosing an appropriate model for the data by which to judge what is normal and what could be an anomaly\n",
    "3. Some practical experience in using z-score and modified z-score in anomaly detection\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:44.688554Z",
     "start_time": "2018-12-11T21:02:43.125292Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import scipy\n",
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python & Library Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:44.698894Z",
     "start_time": "2018-12-11T21:02:44.690882Z"
    }
   },
   "outputs": [],
   "source": [
    "packages = [matplotlib, np, pd, scipy]\n",
    "\n",
    "msg = f\"\"\"\n",
    "Python Version: {sys.version}\n",
    "\n",
    "library .      version\n",
    "-------        -------\"\"\"\n",
    "print(msg)\n",
    "\n",
    "for package in packages:\n",
    "    print(f\"{package.__name__:11}    {package.__version__:>7}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Overview of Anomaly Detection\n",
    "\n",
    "In this lesson, we will use the z-score and modified z-score to detect anomalies in real-world data. Initially, we will use a dataset where anomaly detection works relatively smoothly. Then, as an exercise, you will work with a dataset where more judgment is required to learn about some of the challenges associated with the z-score and modified z-score. \n",
    "\n",
    "### The workflow\n",
    "\n",
    "As we discussed in the lecture, this is workflow:\n",
    "\n",
    "    - Make a model for your data\n",
    "    - Choose a scoring method\n",
    "    - Choose a cutoff above/below which the points are anomalies\n",
    "    - Look at these anomalies and see if the analysis makes sense\n",
    "\n",
    "*CAUTION*: While exploring the data before working with it is strongly encouraged, it is inappropriate to use this exploration to decide what the cutoff should be for the scoring method. If you do this, all you will get are the outliers you have already chosen during your exploration. The modeling, scoring and cutoff choices should be made without bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Z-Score in Actionâ€”Student Participation in Standardized Testing\n",
    "\n",
    "Let's start with an example where anomaly detection works smoothly. We'll examine student participation in standardized testing. Specifically, we will look at student participation rates in the SAT in Connecticut school districts in 2012. The raw data is available here:\n",
    "\n",
    "https://catalog.data.gov/dataset/sat-district-participation-and-performance-2012-2013\n",
    "\n",
    "The data was cleaned so that missing values were removed, percentages were converted into decimals and only essential data for 2012 was retained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this section is to identify schools with low participation rates as a first step in helping these schools improve their participation rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data as a pandas dataframe and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:44.728000Z",
     "start_time": "2018-12-11T21:02:44.701535Z"
    }
   },
   "outputs": [],
   "source": [
    "ct_test = pd.read_csv('SAT_CT_District_Participation_2012.csv') \n",
    "print(ct_test.shape)\n",
    "ct_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 130 schools. For convenience we will use the index number as a numeric label for each school district and use the name when appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start by assuming that the data can be modeled with a normal distribution (we will check this later). And we will use the z-score to identify anomalies. As we are concerned about low participation rates, our cutoff will be a negative number---we are looking for schools with participation rates below the mean. Here we choose $z=-2$. That is, any school with a z-score below -2 will be labeled as an anomaly. \n",
    "\n",
    "If the participation rates are indeed distributed normally, then 95% of the data should be within two standard deviations of the mean. In other words, the anomalies for our threshold lie in the 2.5% left tail of the distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for bigger datasets, larger absolute values of $z$ (typically $z = 3$) are often used as a threshold. Because we have a small dataset, a large value of $z$ might lead to no data being labeled as an anomaly. Also, we were conservative in our choice of $z$ because we want to help as many schools as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could just go ahead and calculate the z-score for the participation rate, but it is good practice to look at fundamental statistics first. Let's calculate the mean and standard deviation. Since the data forms the whole population, we will report the population standard deviation (as opposed to the sample standard deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:44.739764Z",
     "start_time": "2018-12-11T21:02:44.731592Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_rate = ct_test['Participation Rate'].mean()\n",
    "\n",
    "# ddof is the degrees of freedom correction \n",
    "# in the calculation of the standard deviation;\n",
    "# for population standard deviation ddof=0\n",
    "stdev_rate = ct_test['Participation Rate'].std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:44.746050Z",
     "start_time": "2018-12-11T21:02:44.742402Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Mean participation rate is {:.3f}'.format(mean_rate))\n",
    "print('Standard deviation is {:.3f}'.format(stdev_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the z-score and add the result to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:44.773759Z",
     "start_time": "2018-12-11T21:02:44.749071Z"
    }
   },
   "outputs": [],
   "source": [
    "zscore_rate = ss.zscore(ct_test['Participation Rate'], ddof=0)\n",
    "ct_test = ct_test.assign(zscore=zscore_rate)\n",
    "ct_test.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now identify the anomalies and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:44.787031Z",
     "start_time": "2018-12-11T21:02:44.778472Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_anomaly(score_data, threshold):\n",
    "    # Mask to plot values above and below threshold in different colors\n",
    "    score_data = score_data.copy().sort_values(ascending=False).values\n",
    "    ranks = np.linspace(1, len(score_data), len(score_data))\n",
    "    mask_outlier = (score_data < threshold)\n",
    "    \n",
    "    \n",
    "    plt.figure(dpi=150)\n",
    "    plt.plot(ranks[~mask_outlier], score_data[~mask_outlier],'o', color='b',label='OK schools')\n",
    "    plt.plot(ranks[mask_outlier], score_data[mask_outlier],'o', color='r', label='anomalies')\n",
    "    plt.axhline(threshold,color='r',label='threshold', alpha=0.5)\n",
    "    plt.legend(loc = 'lower left')\n",
    "    plt.title('Z-score vs. school district', fontweight='bold')\n",
    "    plt.xlabel('Ranked School district')\n",
    "    plt.ylabel('Z-score')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:45.094359Z",
     "start_time": "2018-12-11T21:02:44.788978Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_anomaly(ct_test['zscore'], -2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, get a list of the schools that are anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:45.107065Z",
     "start_time": "2018-12-11T21:02:45.096593Z"
    }
   },
   "outputs": [],
   "source": [
    "zscore_anomalies = ct_test[(ct_test['zscore'] < -2)]\n",
    "zscore_anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found our anomalies, but we still have one thing to do: check our assumption that the data can be modeled approximately as a normal distribution. If this is the case, then we have completed our test. If it isn't, then we cannot connect the z-score with probabilities as we did earlier in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's bin the data and see what it looks like as a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:45.286052Z",
     "start_time": "2018-12-11T21:02:45.109261Z"
    }
   },
   "outputs": [],
   "source": [
    "nbins= 20\n",
    "n_hist, bins_hist, patches_hist = plt.hist(ct_test['Participation Rate'], nbins, density=False,\n",
    "                           cumulative=False, linewidth=1.0, label='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This histogram has two maxima and is skewed left, so it is not likely to be normal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare the cumulative distribution function for our data with the CDF of a normal distribution with the same mean and standard deviation of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:45.472086Z",
     "start_time": "2018-12-11T21:02:45.288361Z"
    }
   },
   "outputs": [],
   "source": [
    "num_bins = 130\n",
    "normal_dist = [random.gauss(mean_rate, stdev_rate) for _ in range(500)]\n",
    "n, bins, patches = plt.hist(ct_test['Participation Rate'], num_bins, density=True, histtype='step',\n",
    "                           cumulative=True, linewidth=1.0, label='data')\n",
    "plt.hist(normal_dist, num_bins, density=True, histtype='step',\n",
    "                           cumulative=True, linewidth=1.0, label='normal distribution')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper left')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0.2,1.0])\n",
    "plt.xlabel('Participation Rate')\n",
    "plt.ylabel('Cumulative probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we see a difference. If these two visual tests had not been decisive, we could carry out numerical test for normality (such as the Shapiro-Wilk test).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though our data is inconsistent with a normal distribution, both the z-score and the modified z-score did help us identify outliers. So while we cannot make any probabilistic claims based on the z-scores, we can confidently focus our these four schools. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Z-Score vs. Modified Z-Scoreâ€”World Cup Top Goal Scorers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now look at a dataset that shows the limitations of z-scores and why the modified z-score can be useful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will at the number of goals scored by the top goalscorer in every World Cup from 1930 through 2018 (21 competitions in total). The raw data is from here:\n",
    "\n",
    "https://en.wikipedia.org/wiki/FIFA_World_Cup_top_goalscorers\n",
    "\n",
    "The data was cleaned and saved as a CSV. Load it as a dataframe and take a look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:45.490433Z",
     "start_time": "2018-12-11T21:02:45.475036Z"
    }
   },
   "outputs": [],
   "source": [
    "# First row is a header row, but the header names are cumbersome. \n",
    "# Skip first row and manually label\n",
    "# Encoding ensures that accents in sames are rendered properly \n",
    "top_goals = pd.read_csv('world_cup_top_goal_scorers.csv', \n",
    "                        encoding='utf-8',  \n",
    "                        names=['Year', 'Player(s)', 'Goals'], skiprows=1)                                                                                \n",
    "top_goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again will start by using the z-score to identify anomalies. As we are interested in the superstars, this time we will have an upper threshold.  We choose $z = +2$. Above this z-score, any player will be labeled as an anomaly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we calculate the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:45.497455Z",
     "start_time": "2018-12-11T21:02:45.492657Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_goals = top_goals['Goals'].mean()\n",
    "stdev_goals = top_goals['Goals'].std(ddof=0)\n",
    "print('Mean number of goals is {:.2f}'.format(mean_goals))\n",
    "print('Standard deviation is {:.2f}'.format(stdev_goals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the z-score for each player and add the result to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:45.513381Z",
     "start_time": "2018-12-11T21:02:45.499739Z"
    }
   },
   "outputs": [],
   "source": [
    "zscore_goals = ss.zscore(top_goals['Goals'], ddof=0)\n",
    "top_goals = top_goals.assign(zscore=zscore_goals)\n",
    "top_goals.head(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, modify the previous plotting function to display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:45.520714Z",
     "start_time": "2018-12-11T21:02:45.515396Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_anomaly_goals(score_data, threshold):\n",
    "    score_data = score_data.copy().sort_values(ascending=False).values\n",
    "    ranks = np.linspace(1, len(score_data), len(score_data))\n",
    "    mask_outlier = (score_data > threshold)\n",
    "    \n",
    "    plt.figure(dpi=150)\n",
    "    plt.plot(ranks[mask_outlier], score_data[mask_outlier], 'o', color='r', label='anomalies')\n",
    "    plt.plot(ranks[~mask_outlier], score_data[~mask_outlier], 'o', color='b', label='typical player')\n",
    "    plt.axhline(threshold,color='r', label='threshold', alpha=0.5)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Z-score vs. player', fontweight='bold')\n",
    "    plt.xticks(np.arange(0, 21, step=2.0))\n",
    "    plt.xlabel('Player Rank')\n",
    "    plt.ylabel('Z-score')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:45.811888Z",
     "start_time": "2018-12-11T21:02:45.523305Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_anomaly_goals(top_goals['zscore'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one player is picked out: Just Fontaine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:45.823892Z",
     "start_time": "2018-12-11T21:02:45.813801Z"
    }
   },
   "outputs": [],
   "source": [
    "zscore_anomalies_players = top_goals[(top_goals['zscore'] > 2)]\n",
    "zscore_anomalies_players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fontaine was indeed an amazing player, but clearly our analysis is flawed. By looking at the plot, we see that in 12 out of 21 competitions, the top goalscorer(s) scored less than the mean number of goals (7.05). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What's going on? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: We are seeing an effect we discussed in lectures---the mean and standard deviation are themselves susceptible to the presence of anomalies. With his 13 goals, the amazing Fontaine is raising the mean so much that most players fall below it. As a result, he becomes the only anomaly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat this analysis with the modified z-score and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:45.833000Z",
     "start_time": "2018-12-11T21:02:45.827261Z"
    }
   },
   "outputs": [],
   "source": [
    "median_goals = np.median(top_goals['Goals'])\n",
    "median_goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the median (6.0) is lower than the mean (7.05) as would be expected from the plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the modified z-score. Recall that in lectures this was defined for each data point $x_{i}$ as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y_{i} = (x_{i} - \\tilde X)/{\\rm MAD}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\tilde X$ is the median of the data and MAD is the median of the absolute deviation from the median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to make a slight modification and introduce a consistency correction $k$, which allows us to use MAD as a consistent estimate for the standard deviation. The value of $k$ depends on the underlying distribution of the data. For simplicity, we will use the value for a normal distribution $k=1.4826$ (see [https://en.wikipedia.org/wiki/Median_absolute_deviation](https://en.wikipedia.org/wiki/Median_absolute_deviation)).\n",
    "\n",
    "**Note:** Correction factor of $k=1.4826$ still assumes the underlying data is normal!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the modified z-score becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y_{i} = (x_{i} - \\tilde X)/(k*{\\rm MAD})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and this is the form we will use in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:45.839766Z",
     "start_time": "2018-12-11T21:02:45.835552Z"
    }
   },
   "outputs": [],
   "source": [
    "def modified_zscore(data, consistency_correction=1.4826):\n",
    "    \"\"\"\n",
    "    Returns the modified z score and Median Absolute Deviation (MAD) from the scores in data.\n",
    "    The consistency_correction factor converts the MAD to the standard deviation for a given\n",
    "    distribution. The default value (1.4826) is the conversion factor if the underlying data\n",
    "    is normally distributed\n",
    "    \"\"\"\n",
    "    median = np.median(data)\n",
    "    \n",
    "    deviation_from_med = np.array(data) - median\n",
    "\n",
    "    mad = np.median(np.abs(deviation_from_med))\n",
    "    mod_zscore = deviation_from_med/(consistency_correction*mad)\n",
    "    return mod_zscore, mad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, compute the modified z-score for all players then plot and list the results. Note that the threshold remains the same at $y = +2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:45.846411Z",
     "start_time": "2018-12-11T21:02:45.842340Z"
    }
   },
   "outputs": [],
   "source": [
    "mod_zscore_goals, mad_goals = modified_zscore(top_goals['Goals'])\n",
    "top_goals = top_goals.assign(mod_zscore=mod_zscore_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:45.854492Z",
     "start_time": "2018-12-11T21:02:45.849249Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_anomaly_goals_2(score_data, threshold):\n",
    "    score_data = score_data.copy().sort_values(ascending=False).values\n",
    "    ranks = np.linspace(1, len(score_data), len(score_data))\n",
    "    mask_outliers = (score_data > threshold)\n",
    "    \n",
    "    plt.figure(dpi=150)\n",
    "    plt.plot(ranks[mask_outliers], score_data[mask_outliers],'o', color='r',label='anomalies')\n",
    "    plt.plot(ranks[~mask_outliers], score_data[~mask_outliers],'o', color='b', label='typical player')\n",
    "    plt.axhline(threshold,color='r',label='threshold', alpha=0.5)\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.title('Modified z-score vs. player', fontweight='bold')\n",
    "    plt.xticks(np.arange(0, 21, step=2.0))\n",
    "    plt.xlabel('Player')\n",
    "    plt.ylabel('Modified z-score')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:46.152457Z",
     "start_time": "2018-12-11T21:02:45.856839Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_anomaly_goals_2(top_goals['mod_zscore'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:46.166568Z",
     "start_time": "2018-12-11T21:02:46.154979Z"
    }
   },
   "outputs": [],
   "source": [
    "mod_zscore_anomalies_players = top_goals[(top_goals['mod_zscore'] > 2)]\n",
    "mod_zscore_anomalies_players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we find four anomalous players."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How does the MAD compare with the standard deviation calculated previously?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T21:02:46.172510Z",
     "start_time": "2018-12-11T21:02:46.168661Z"
    }
   },
   "outputs": [],
   "source": [
    "print('The value of MAD is {:.2f}'.format(mad_goals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and $k*{\\rm MAD}$ is 1.48, which is smaller than the standard deviation (2.05). We see that the anomalies have a larger effect on the standard deviation, which depends on the square of the deviation from the mean (MAD depends linearly on the deviation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the data for top goal scorers is not normally distributed, so we can't associated probabilities with our scores, but our analysis does show the need to think about the scoring method used with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise #1\n",
    "This exercise refers to the SAT participation rates.\n",
    "\n",
    "A. Repeat the analysis using the modified z-score.\n",
    "\n",
    "B. Do you find the same anomalies? \n",
    "\n",
    "C. Discuss your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this assignment you should have learned: \n",
    "1. How anomaly detection can be implemented as an algorithm\n",
    "2. The importance of chosing an appropriate model and anomaly score\n",
    "3. Some practical experience in using z-score and modified z-score in anomaly detection\n",
    "\n",
    "Congratulations! This concludes the lesson."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Intel Anomaly Env",
   "language": "python",
   "name": "intel_anomaly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
