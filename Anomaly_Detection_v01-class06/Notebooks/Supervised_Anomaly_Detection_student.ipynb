{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2019 Intel Corporation\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In Lesson 6 of *Anomaly Detection*, we learned that if training data is available, supervised anomaly detection can be used, which converts the anomaly detection problem into a classification problem albeit one with special challenges. In the lecture we focused on one common challenge: class imbalance, which arises because anomalies are rare (by definition). \n",
    "\n",
    "Here will detect anomalies in simulated datasets using cost-sensitive learning, adaptive resampling and boosting methods.\n",
    "\n",
    "\n",
    "# Learning Outcomes\n",
    "\n",
    "You should walk away from this Python tutorial with:\n",
    "\n",
    "1. An understanding of supervised anomaly detection \n",
    "2. Some practical experience with cost-sensitive learning, adaptive resampling and boosting methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "This notebook uses two packages that may require installation:\n",
    "\n",
    "1. Mlxtend (machine learning extensions), which is a Python library of useful tools for data science tasks.\n",
    "(http://rasbt.github.io/mlxtend/)\n",
    "\n",
    "\n",
    "2. imbalance-learn, which is a Python package offering resampling techniques commonly used in datasets showing strong class imbalance\n",
    "(https://imbalanced-learn.org/en/stable/index.html)\n",
    "\n",
    "Installation instruction are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "from collections import Counter\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python and library versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versions = ( (\"matplotlib\", matplotlib.__version__),\n",
    "            (\"numpy\", np.__version__),\n",
    "            (\"pandas\", pd.__version__))\n",
    "\n",
    "print(sys.version, \"\\n\")\n",
    "print(\"library\" + \" \" * 4 + \"version\")\n",
    "print(\"-\" * 18)\n",
    "\n",
    "for tup1, tup2 in versions:\n",
    "    print(\"{:11} {}\".format(tup1, tup2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Cost-sensitive learning\n",
    "\n",
    "In this section, we are going to use simulated data to examine cost-sensitive learning. Our supervised anomaly detection will be done using a decision tree classifier (https://scikit-learn.org/stable/modules/tree.html#tree).\n",
    "\n",
    "We will proceed as follows:\n",
    "\n",
    "1. Create the simulated data\n",
    "2. Train our algorithm giving all data points equal weight \n",
    "3. Examine the misclassifications using a confusion matrix \n",
    "4. Repeat steps (2) and (3) using cost-sensitive learning and compare our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the synthetic data using the *make_classification* function of sklean. We create 5000 points with approximately 90% normal points (label 0) and 10% anomalies (label 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic imbalanced data \n",
    "features, label = make_classification(n_samples=5000, n_features=2, \n",
    "                                      n_informative=2, n_redundant=0, \n",
    "                                      n_repeated=0, n_classes=2, \n",
    "                                      n_clusters_per_class=1,\n",
    "                                      weights=[0.90, 0.10], flip_y=0.01,\n",
    "                                      class_sep=1.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a detailed explanation of the *make_classification* parameters, see https://scikitlearn.org/stable/modules/generated/sklearn.datasets.make_classification.html. \n",
    "\n",
    "Here we discuss a few of them.\n",
    "\n",
    "We specify the initial weights of the normal and anomaly class to be 0.90 and 0.10 respectively using *weights*.\n",
    "\n",
    "With *flip_y*, we specify the fraction of samples whose class are randomly exchanged to introduce some noise into the data.\n",
    "\n",
    "And we use *class_sep* to specify the separation between the two classes; larger values spread out the classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(features, columns=['feature1', 'feature2'])\n",
    "df['label'] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data and color code normal vs. anomaly. Here we use *lmplot* from *seaborn* as it offers a compact way to label points by class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'red']\n",
    "sns.lmplot('feature1', 'feature2', data=df, hue='label',\n",
    "           palette=colors, fit_reg=False, scatter_kws={'s': 20})\n",
    "plt.gcf().set_size_inches(6,4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we train our classifier. We will use a decision tree with a single split (often called a decision stump). This tree makes a decision based on a single input feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plain tree as \n",
    "tree_plain = DecisionTreeClassifier(max_depth=1, class_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use *plot_decision_regions* from *mlxtend* to show the regions the classfier uses to assign class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_plain_fit = tree_plain.fit(features, label)\n",
    "plot_decision_regions(features, label, tree_plain_fit)\n",
    "plt.title(f'SVC with Label = {Counter(label)}')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend(loc='best')\n",
    "plt.gcf().set_size_inches(6,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the two classes are separated by a single line as only one feature was used for the split. \n",
    "\n",
    "Next, we examined the statistics of the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_tree_plain=confusion_matrix(label, tree_plain.predict(features))\n",
    "print(cm_tree_plain)\n",
    "accuracy_tree_plain = accuracy_score(label, tree_plain.predict(features))\n",
    "print(f'Accuracy: {accuracy_tree_plain}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We misclassified 37 normal points and 47 anomalies. Not bad, but let's try to improve this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, we will introduce cost-sensitive learning. For our decision tree, cost-sensitive learning can be introduced through the parameter *class_weight*. In the previous analysis, this parameter was set to *None*, which means that all points were given equal weight. \n",
    "\n",
    "In our next iteration, we will set *class_weight* to *balanced*. In this case, the weights are set inversely proportional to the frequency of the class. That is, the cost of making a mistake is inversely proportional to the number of instances of that class, which is the example we discussed in the lecture. \n",
    "\n",
    "For more details, see https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_bal = DecisionTreeClassifier(max_depth=1, class_weight='balanced')\n",
    "tree_bal_fit = tree_bal.fit(features, label)\n",
    "plot_decision_regions(features, label, tree_bal_fit)\n",
    "plt.title(f'SVC with Label = {Counter(label)}')\n",
    "plt.xlabel('Feature_1')\n",
    "plt.ylabel('Feature_2')\n",
    "plt.legend(loc='best')\n",
    "plt.gcf().set_size_inches(6,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the boundary has moved. It is now closer to Feature_2 = 0. This is promising. It shows that the cost-sensitive learning has had an effect on the classification. Is it for the better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_tree_bal=confusion_matrix(label, tree_bal.predict(features))\n",
    "print(cm_tree_bal)\n",
    "accuracy_tree_bal = accuracy_score(label, tree_bal.predict(features))\n",
    "print(f'Accuracy: {accuracy_tree_bal}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy has dropped and we misclassified more normal points (98 vs. 37 previously). \n",
    "\n",
    "However, we improved our classification of anomalies. Only 27 were misclassified (vs. 47 before). If what matters most to us are the anomalies, the lower misclassification rate is a significant improvement.\n",
    "\n",
    "Cost-sensitive learning is doing what it is meant to do: help detect anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Adaptive resampling \n",
    "\n",
    "In this section, we are going to use the data from the previous section to illustrate the adaptive resampling. Our supervised anomaly detection will be done using support vector classification—SVC (https://scikit-learn.org/stable/modules/svm.html#svm-classification).\n",
    "\n",
    "\n",
    "We will proceed as we did before:\n",
    "\n",
    "1. Train our anomaly detection algorithm without any resampling \n",
    "2. Calculate the cost of our misclassification\n",
    "3. Repeat steps (2) and (3) using adaptive resampling and compare our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we build our classifier using the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC().fit(features, label)\n",
    "plot_decision_regions(features, label, clf)\n",
    "plt.title(f'SVC with Label = {Counter(label)}')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend(loc='best')\n",
    "plt.gcf().set_size_inches(6,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see (from the title of the plot) that we have 521 anomalies and 4479 normal points. That is, 10.4% of the points are anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the confusion matrix to see how well our classifier works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(label, clf.predict(features))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things clearer, we print out each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f'True Negative: {tn}')\n",
    "print(f'False Positive: {fp}')\n",
    "print(f'False Negative: {fn}')\n",
    "print(f'True Positive: {tp}')\n",
    "accuracy = accuracy_score(label, clf.predict(features))\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, we misclassified 18 normal points and 40 anomalies. Can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first attempt to improve, let's oversample the anomaly class. We will use *RandomOverSampler* from *imblearn* to created a resampled training dataset. \n",
    "\n",
    "Essential input: how much we want to oversample the anomaly class. Here we will specify the oversampling as a fraction of the size of the normal class. This fraction, *resample_ratio*, should meet two conditions:\n",
    "\n",
    "1. It should be less than or equal to 1, so that the anomaly class always remain a minority. \n",
    "\n",
    "2. The fraction should be large enough than the number of anomaly points in the resampled dataset is larger that the number in the original dataset. Otherwise, we will be undersampling the anomaly class.\n",
    "\n",
    "Violating either condition produces a warning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random oversampling of the anomaly class\n",
    "resample_ratio = 0.3 # (anomalies / normal) after resampling\n",
    "sample_normal = tn + fp # total number of true normal points\n",
    "sample_anomaly = int(resample_ratio*sample_normal) # must be an integer\n",
    "sampling_dict = {0: sample_normal, 1: sample_anomaly}\n",
    "ros = RandomOverSampler(ratio=sampling_dict, random_state=0) \n",
    "features_resampled, label_resampled = ros.fit_sample(features,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show how many points in each class after resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(label_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ros = SVC().fit(features_resampled, label_resampled)\n",
    "plot_decision_regions(features_resampled, label_resampled, clf_ros)\n",
    "plt.title(f'Oversampled SVC with Label = {Counter(label_resampled)}')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.gcf().set_size_inches(6,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we show the confusion matrix and individual categories for our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_ros = confusion_matrix(label, clf_ros.predict(features))\n",
    "cm_ros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_ros, fp_ros, fn_ros, tp_ros = cm_ros.ravel()\n",
    "print('After Random Oversampling')\n",
    "print(f'True Negative: {tn_ros}')\n",
    "print(f'False Positive: {fp_ros}')\n",
    "print(f'False Negative: {fn_ros}')\n",
    "print(f'True Positive: {tp_ros}')\n",
    "accuracy_ros = accuracy_score(label, clf_ros.predict(features))\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now have misclassified 28 normal points and 34 anomalies.\n",
    "\n",
    "Previously, we misclassified 18 normal points and 40 anomalies. \n",
    "\n",
    "Which is better? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer depends on the cost of misclassification. \n",
    "\n",
    "Let us define a function that calculates this cost. In the function below, we are implicitly assuming that a correctly classified point has no cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misclass_cost(false_pos, false_neg, false_pos_cost, false_neg_cost):\n",
    "    '''\n",
    "    Calculates the cost of misclassified instances\n",
    "   \n",
    "    Args: \n",
    "        false_pos: number of false positives (float)\n",
    "        false_neg: number of false negatives (float)\n",
    "        false_pos_cost: cost of a false positive (float > 0)\n",
    "        false_neg_cost: cost of a false negative (float > 0)\n",
    "        \n",
    "    Returns: \n",
    "        misclass_cost: the cost of misclassifcation (float)\n",
    "        \n",
    "    Raises:\n",
    "        Error: if false_pos_cost or false_neg_cost are non-positive\n",
    "    '''\n",
    "    if(false_pos_cost <= 0  or false_neg_cost <= 0):\n",
    "        print('Costs must be greater than zero')\n",
    "        return\n",
    "    else:\n",
    "        misclass_cost = (false_pos*false_pos_cost \n",
    "                         + false_neg*false_neg_cost)\n",
    "        return misclass_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to assign costs. We will follow the approach described in the lecture for the screening test, where the cost for a false negative is greater than for a false positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pos_cost = 10\n",
    "false_neg_cost = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can calculate the cost from the regular dataset and the randomly oversampled one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_reg = misclass_cost(fp, fn, false_pos_cost, false_neg_cost)\n",
    "cost_ros = misclass_cost(fp_ros, fn_ros, false_pos_cost, false_neg_cost)\n",
    "print(f'Without oversampling the cost is: {cost_reg}')\n",
    "print(f'With random oversampling the cost is: {cost_ros}')\n",
    "print('')\n",
    "print(f'Accuracy without oversampling is: {accuracy}')\n",
    "print(f'Accuracy with random oversampling is: {accuracy_ros}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random oversampling has reduced the cost of misclassification despite the lower accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What happens if the costs for false positive and false negative are equal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: The cost will be proportional to (1-accuracy). In other words, using accuracy as a metric is equivalent to assuming equal costs for the two categories. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how undersampling does. The structure of this section is the same as for oversampling, except that now we undersample the normal class.\n",
    "\n",
    "As before, we have an essential input: how much we want to undersample the normal class. Here we will specify the undersampling as a multiple of the size of the anomaly class. This multiple, *resample_ratio_under*, should meet two conditions:\n",
    "\n",
    "1. It should be greater than or equal to 1, so that the normal class always remain a majority. \n",
    "\n",
    "2. The multiple should be small enough than the number of normal points in the resampled dataset is smaller that the number in the original dataset. Otherwise, we will be oversampling the normal class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random undersampling of the normal class\n",
    "\n",
    "# resample_ratio_under is (normal/anomalies) after resampling\n",
    "# Should be int, but added int() later to prevent error\n",
    "resample_ratio_under = 1 # a 1:1 ratio is a typical starting point\n",
    "\n",
    "sample_anomaly_under = tp + fn \n",
    "\n",
    "# total number of true normal points\n",
    "# int is a safeguard in case resample_ratio_under is given as float\n",
    "sample_normal_under = int(resample_ratio_under*sample_anomaly_under)\n",
    "\n",
    "sampling_dict = {0: sample_normal_under, 1: sample_anomaly_under}\n",
    "rus = RandomUnderSampler(ratio=sampling_dict, random_state=0) \n",
    "features_resampled_2, label_resampled_2 = rus.fit_sample(features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check undersampling \n",
    "Counter(label_resampled_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, omit plot and just calculate statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rus = SVC().fit(features_resampled_2, label_resampled_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rus = confusion_matrix(label, clf_rus.predict(features))\n",
    "print(cm_rus)\n",
    "accuracy_rus = accuracy_score(label, clf_rus.predict(features))\n",
    "tn_rus, fp_rus, fn_rus, tp_rus = cm_rus.ravel()\n",
    "cost_rus = misclass_cost(fp_rus, fn_rus, false_pos_cost, false_neg_cost)\n",
    "print('')\n",
    "print(f'With random undersampling the cost is: {cost_rus}')\n",
    "print(f'Accuracy with random undersampling is: {accuracy_rus}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling does even better than oversampling in terms of cost despite the further drop in accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: AdaBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to examine boosting methods. More specifically, we will look at adaptive boosting (AdaBoost). \n",
    "\n",
    "As we discussed in the lecture, AdaBoost works well with any weak learner, but it most commonly used with decision trees. Therefore, it this section we will apply it to the plain tree from Section 1 (where *class_weight* is *None*) and see if it improves our results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdtree = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1, \n",
    "                                                   class_weight=None),\n",
    "                            n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost introduces extra paramaters that must be specified. The only parameter we will change from the default value is *n_estimators*, which is the maximum number of estimators at which boosting is terminated.\n",
    "\n",
    "A complete list of parameters is here: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdtree_fit = bdtree.fit(features, label)\n",
    "plot_decision_regions(features, label, bdtree_fit)\n",
    "plt.title(f'SVC with Label = {Counter(label)}')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend(loc='best')\n",
    "plt.gcf().set_size_inches(6,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost has created a more complex decision boundary. It is no longer a single straight line. Have the statistics improved too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_bdtree=confusion_matrix(label, bdtree.predict(features))\n",
    "print(cm_bdtree)\n",
    "accuracy_bdtree = accuracy_score(label, bdtree.predict(features))\n",
    "print(f'Accuracy: {accuracy_bdtree}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the results without boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm_tree_plain)\n",
    "print(f'Accuracy: {accuracy_tree_plain}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting has increased the accuracy and even improved slightly the number of anomalies detected correctly (478 vs. 474) Useful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise #1\n",
    "\n",
    "This exercise refers to Section 2 (adaptive resampling). \n",
    "\n",
    "We found that undersampling gave the lowest cost of misclassification for the costs we specified. However, we did not check whether our undersampling ratio was optimal. Could a different value *resample_ratio_under* lower our cost even more?\n",
    "\n",
    "Write a function to calculate the misclassification cost for a suitable range of *resample_ratio_under* and find the ratio that leads to the lowest cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise #2\n",
    "\n",
    "This exercise refers to Section 3 (AdaBoost).\n",
    "\n",
    "Repeat the analysis of Section 3 with the balanced decision trees (*class_weight*=*balanced*). Does boosting lead again to an improvement is anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this assignment you should have learned: \n",
    "\n",
    "1. How to use supervised anomaly detection\n",
    "2. How to implement cost-sensitive learning, adaptive resampling and boosting methods.\n",
    "\n",
    "Congratulations! This concludes the lesson."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Intel Anomaly Env",
   "language": "python",
   "name": "intel_anomaly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
